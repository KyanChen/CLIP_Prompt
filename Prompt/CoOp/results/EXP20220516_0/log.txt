***************
** Arguments **
***************
backbone: 
config_file: configs/my_trainers/rn50_ep50.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: []
output_dir: None
resume: 
root: None
seed: -1
source_domains: None
target_domains: None
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 1
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 256
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 256
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: VAW
  NUM_LABELED: -1
  NUM_SHOTS: 4
  ROOT: data/
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: True
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  SIZE: (224, 224)
  TRANSFORMS: ()
MODEL:
  BACKBONE:
    NAME: RN50
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 100
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: results/EXP20220516_0
RESUME: 
SEED: -1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: True
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 15
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CG:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  COOP:
    CLASS_TOKEN_POSITION: middle
    CSC: False
    CTX_INIT: None
    N_CTX: 16
    PREC: fp16
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEA:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.10.0+cu111
Is debug build: False
CUDA used to build PyTorch: 11.1
ROCM used to build PyTorch: N/A

OS: CentOS Linux release 7.8.2003 (Core) (x86_64)
GCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)
Clang version: Could not collect
CMake version: version 2.8.12.2
Libc version: glibc-2.17

Python version: 3.8.12 (default, Oct 12 2021, 13:49:34)  [GCC 7.5.0] (64-bit runtime)
Python platform: Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: Could not collect
GPU models and configuration: 
GPU 0: A100-SXM4-40GB
GPU 1: A100-SXM4-40GB
GPU 2: A100-SXM4-40GB
GPU 3: A100-SXM4-40GB
GPU 4: A100-SXM4-40GB
GPU 5: A100-SXM4-40GB
GPU 6: A100-SXM4-40GB
GPU 7: A100-SXM4-40GB

Nvidia driver version: 455.23.05
cuDNN version: Probably one of the following:
/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn.so.8
/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8
/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_adv_train.so.8
/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8
/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8
/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8
/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_ops_train.so.8
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] numpy==1.20.3
[pip3] torch==1.10.0+cu111
[pip3] torchvision==0.11.1+cu111
[conda] numpy                     1.20.3                   pypi_0    pypi
[conda] torch                     1.10.0+cu111             pypi_0    pypi
[conda] torchvision               0.11.1+cu111             pypi_0    pypi
        Pillow (8.4.0)

Loading trainer: CoOp
Loading dataset: VAW
train :  216790
val :  12286
test :  31819
Loading preprocessed few-shot data from /data/kyanchen/clip_prompt/CoOp/data/VAW/split_fewshot/shot_4-seed_-1.pkl
train :  2480
val :  32646
test :  121108
Note: no transform is applied!
Note: no transform is applied!
***** Dataset statistics *****
  Dataset: VAW
  # classes: 620
  # train_x: 2,480
  # val: 32,646
  # test: 121,108
Loading CLIP (backbone: RN50)
Building custom CLIP
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Turning off gradients in both the image and the text encoder
Loading evaluator: Classification
No checkpoint found, train from scratch
Initializing summary writer for tensorboard with log_dir=results/EXP20220516_0/tensorboard
epoch [1/100][5/9]	time 1.817 (2.085)	data 1.176 (1.169)	eta 0:31:05	loss 7.8954 (8.7139)	acc 0.5800 (0.5633)	lr 1.000000e-05
epoch [2/100][5/9]	time 1.975 (2.135)	data 1.334 (1.486)	eta 0:31:31	loss 1.1810 (2.5425)	acc 0.4881 (0.4601)	lr 2.000000e-03
epoch [3/100][5/9]	time 1.924 (2.102)	data 1.274 (1.453)	eta 0:30:43	loss 1.1295 (1.1082)	acc 0.4368 (0.4476)	lr 1.999507e-03
epoch [4/100][5/9]	time 2.097 (2.212)	data 1.439 (1.554)	eta 0:31:59	loss 0.9972 (1.0840)	acc 0.4744 (0.4587)	lr 1.998027e-03
epoch [5/100][5/9]	time 2.019 (2.145)	data 1.366 (1.495)	eta 0:30:42	loss 1.0402 (1.0978)	acc 0.4611 (0.4630)	lr 1.995562e-03
epoch [6/100][5/9]	time 1.838 (2.117)	data 1.192 (1.464)	eta 0:29:59	loss 1.0637 (1.0831)	acc 0.4156 (0.4385)	lr 1.992115e-03
epoch [7/100][5/9]	time 1.976 (2.108)	data 1.347 (1.468)	eta 0:29:33	loss 1.0558 (1.0466)	acc 0.5032 (0.4574)	lr 1.987688e-03
epoch [8/100][5/9]	time 1.918 (2.079)	data 1.288 (1.440)	eta 0:28:49	loss 0.9637 (0.9781)	acc 0.4198 (0.4611)	lr 1.982287e-03
epoch [9/100][5/9]	time 2.024 (2.158)	data 1.376 (1.499)	eta 0:29:36	loss 0.9692 (0.9650)	acc 0.4255 (0.4386)	lr 1.975917e-03
epoch [10/100][5/9]	time 1.892 (2.165)	data 1.255 (1.508)	eta 0:29:22	loss 1.0284 (0.9878)	acc 0.4645 (0.4632)	lr 1.968583e-03
epoch [11/100][5/9]	time 1.828 (2.146)	data 1.192 (1.498)	eta 0:28:47	loss 1.0134 (0.9420)	acc 0.3978 (0.4463)	lr 1.960294e-03
epoch [12/100][5/9]	time 1.967 (2.143)	data 1.332 (1.505)	eta 0:28:25	loss 1.0389 (0.9571)	acc 0.4579 (0.4623)	lr 1.951057e-03
epoch [13/100][5/9]	time 1.951 (2.131)	data 1.322 (1.491)	eta 0:27:57	loss 0.8875 (0.8971)	acc 0.4972 (0.4566)	lr 1.940881e-03
epoch [14/100][5/9]	time 1.854 (2.163)	data 1.219 (1.523)	eta 0:28:02	loss 0.9413 (0.9050)	acc 0.5024 (0.4801)	lr 1.929776e-03
epoch [15/100][5/9]	time 1.903 (2.096)	data 1.268 (1.454)	eta 0:26:51	loss 0.9081 (0.9017)	acc 0.4732 (0.4624)	lr 1.917755e-03
Checkpoint saved to "results/EXP20220516_0/prompt_learner/model.pth.tar-15"
epoch [16/100][5/9]	time 2.001 (2.164)	data 1.375 (1.515)	eta 0:27:24	loss 0.8726 (0.8813)	acc 0.4773 (0.4685)	lr 1.904827e-03
epoch [17/100][5/9]	time 1.970 (2.177)	data 1.340 (1.532)	eta 0:27:14	loss 0.9649 (0.9067)	acc 0.3890 (0.4544)	lr 1.891007e-03
epoch [18/100][5/9]	time 1.915 (2.108)	data 1.292 (1.474)	eta 0:26:04	loss 0.9451 (0.8803)	acc 0.4930 (0.4710)	lr 1.876307e-03
epoch [19/100][5/9]	time 1.885 (2.040)	data 1.264 (1.407)	eta 0:24:55	loss 0.8803 (0.8866)	acc 0.4282 (0.4551)	lr 1.860742e-03
epoch [20/100][5/9]	time 1.890 (2.113)	data 1.242 (1.468)	eta 0:25:29	loss 0.8574 (0.8659)	acc 0.4719 (0.4491)	lr 1.844328e-03
epoch [21/100][5/9]	time 1.879 (2.080)	data 1.253 (1.441)	eta 0:24:47	loss 0.9097 (0.8632)	acc 0.4660 (0.4595)	lr 1.827081e-03
epoch [22/100][5/9]	time 1.931 (2.142)	data 1.305 (1.505)	eta 0:25:12	loss 0.8244 (0.8332)	acc 0.4505 (0.4683)	lr 1.809017e-03
epoch [23/100][5/9]	time 1.917 (2.128)	data 1.288 (1.491)	eta 0:24:43	loss 0.8087 (0.8431)	acc 0.4837 (0.4620)	lr 1.790155e-03
epoch [24/100][5/9]	time 2.031 (2.145)	data 1.400 (1.504)	eta 0:24:35	loss 0.8838 (0.8489)	acc 0.4782 (0.4810)	lr 1.770513e-03
epoch [25/100][5/9]	time 1.939 (2.093)	data 1.309 (1.457)	eta 0:23:40	loss 0.9196 (0.8615)	acc 0.4447 (0.4776)	lr 1.750111e-03
epoch [26/100][5/9]	time 2.001 (2.183)	data 1.371 (1.542)	eta 0:24:22	loss 0.8875 (0.8324)	acc 0.4182 (0.4608)	lr 1.728969e-03
epoch [27/100][5/9]	time 1.992 (2.121)	data 1.356 (1.475)	eta 0:23:21	loss 0.9021 (0.8441)	acc 0.4405 (0.4500)	lr 1.707107e-03
epoch [28/100][5/9]	time 1.931 (2.126)	data 1.299 (1.487)	eta 0:23:05	loss 0.8508 (0.8388)	acc 0.5039 (0.4775)	lr 1.684547e-03
epoch [29/100][5/9]	time 1.885 (2.019)	data 1.254 (1.375)	eta 0:21:38	loss 0.8547 (0.8334)	acc 0.4341 (0.4699)	lr 1.661312e-03
epoch [30/100][5/9]	time 1.983 (2.152)	data 1.362 (1.523)	eta 0:22:44	loss 0.7721 (0.8123)	acc 0.4524 (0.4580)	lr 1.637424e-03
Checkpoint saved to "results/EXP20220516_0/prompt_learner/model.pth.tar-30"
epoch [31/100][5/9]	time 1.899 (2.101)	data 1.280 (1.464)	eta 0:21:53	loss 0.8146 (0.7925)	acc 0.4186 (0.4507)	lr 1.612907e-03
epoch [32/100][5/9]	time 1.970 (2.093)	data 1.333 (1.448)	eta 0:21:29	loss 0.7937 (0.7876)	acc 0.4820 (0.4690)	lr 1.587785e-03
epoch [33/100][5/9]	time 1.973 (2.133)	data 1.348 (1.499)	eta 0:21:34	loss 0.8267 (0.8052)	acc 0.4785 (0.4705)	lr 1.562083e-03
epoch [34/100][5/9]	time 1.882 (2.108)	data 1.267 (1.477)	eta 0:21:00	loss 0.8060 (0.8134)	acc 0.4805 (0.4540)	lr 1.535827e-03
epoch [35/100][5/9]	time 1.943 (2.079)	data 1.327 (1.451)	eta 0:20:24	loss 0.8197 (0.8109)	acc 0.4287 (0.4508)	lr 1.509041e-03
epoch [36/100][5/9]	time 1.953 (2.130)	data 1.327 (1.495)	eta 0:20:35	loss 0.8177 (0.7974)	acc 0.4546 (0.4608)	lr 1.481754e-03
epoch [37/100][5/9]	time 1.907 (2.106)	data 1.272 (1.479)	eta 0:20:02	loss 0.8493 (0.8050)	acc 0.4202 (0.4586)	lr 1.453990e-03
epoch [38/100][5/9]	time 2.001 (2.108)	data 1.379 (1.479)	eta 0:19:44	loss 0.7932 (0.7964)	acc 0.4471 (0.4717)	lr 1.425779e-03
epoch [39/100][5/9]	time 1.878 (2.087)	data 1.261 (1.456)	eta 0:19:14	loss 0.8094 (0.7855)	acc 0.4273 (0.4798)	lr 1.397148e-03
epoch [40/100][5/9]	time 1.912 (2.106)	data 1.277 (1.473)	eta 0:19:05	loss 0.7679 (0.8017)	acc 0.4400 (0.4496)	lr 1.368125e-03
epoch [41/100][5/9]	time 1.905 (2.086)	data 1.281 (1.456)	eta 0:18:35	loss 0.7843 (0.7873)	acc 0.4356 (0.4788)	lr 1.338738e-03
epoch [42/100][5/9]	time 1.898 (2.045)	data 1.278 (1.417)	eta 0:17:55	loss 0.7636 (0.7871)	acc 0.4776 (0.4589)	lr 1.309017e-03
epoch [43/100][5/9]	time 1.972 (2.048)	data 1.349 (1.423)	eta 0:17:38	loss 0.7784 (0.7557)	acc 0.3905 (0.4530)	lr 1.278991e-03
epoch [44/100][5/9]	time 1.855 (2.072)	data 1.238 (1.442)	eta 0:17:32	loss 0.7402 (0.7728)	acc 0.4696 (0.4639)	lr 1.248690e-03
epoch [45/100][5/9]	time 1.872 (2.041)	data 1.246 (1.396)	eta 0:16:58	loss 0.7519 (0.7787)	acc 0.4576 (0.4727)	lr 1.218143e-03
Checkpoint saved to "results/EXP20220516_0/prompt_learner/model.pth.tar-45"
epoch [46/100][5/9]	time 1.967 (2.135)	data 1.340 (1.499)	eta 0:17:25	loss 0.7547 (0.8034)	acc 0.4867 (0.4580)	lr 1.187381e-03
epoch [47/100][5/9]	time 1.890 (2.145)	data 1.261 (1.507)	eta 0:17:11	loss 0.8244 (0.7716)	acc 0.4465 (0.4592)	lr 1.156434e-03
epoch [48/100][5/9]	time 1.889 (2.126)	data 1.254 (1.489)	eta 0:16:43	loss 0.7510 (0.7522)	acc 0.4870 (0.4924)	lr 1.125333e-03
epoch [49/100][5/9]	time 1.896 (2.166)	data 1.268 (1.524)	eta 0:16:42	loss 0.7809 (0.7528)	acc 0.4385 (0.4397)	lr 1.094108e-03
epoch [50/100][5/9]	time 1.921 (2.175)	data 1.296 (1.538)	eta 0:16:27	loss 0.7761 (0.7471)	acc 0.4944 (0.4485)	lr 1.062791e-03
epoch [51/100][5/9]	time 2.060 (2.165)	data 1.430 (1.525)	eta 0:16:03	loss 0.7910 (0.7852)	acc 0.4796 (0.4709)	lr 1.031411e-03
epoch [52/100][5/9]	time 1.916 (2.146)	data 1.288 (1.511)	eta 0:15:35	loss 0.7773 (0.7500)	acc 0.4132 (0.4346)	lr 1.000000e-03
epoch [53/100][5/9]	time 1.986 (2.162)	data 1.323 (1.519)	eta 0:15:23	loss 0.7054 (0.7673)	acc 0.4753 (0.4736)	lr 9.685892e-04
epoch [54/100][5/9]	time 1.932 (2.128)	data 1.313 (1.497)	eta 0:14:49	loss 0.7299 (0.7698)	acc 0.4917 (0.4568)	lr 9.372095e-04
epoch [55/100][5/9]	time 1.906 (2.066)	data 1.278 (1.433)	eta 0:14:04	loss 0.7541 (0.7301)	acc 0.4962 (0.4620)	lr 9.058917e-04
epoch [56/100][5/9]	time 1.846 (2.068)	data 1.214 (1.425)	eta 0:13:47	loss 0.7340 (0.7601)	acc 0.4962 (0.4568)	lr 8.746668e-04
epoch [57/100][5/9]	time 1.915 (2.083)	data 1.277 (1.436)	eta 0:13:34	loss 0.7233 (0.7505)	acc 0.4231 (0.4535)	lr 8.435655e-04
epoch [58/100][5/9]	time 2.069 (2.105)	data 1.406 (1.457)	eta 0:13:24	loss 0.7413 (0.7372)	acc 0.4738 (0.4704)	lr 8.126187e-04
epoch [59/100][5/9]	time 1.911 (2.111)	data 1.284 (1.471)	eta 0:13:07	loss 0.7449 (0.7485)	acc 0.4450 (0.4525)	lr 7.818568e-04
epoch [60/100][5/9]	time 1.916 (2.047)	data 1.298 (1.416)	eta 0:12:25	loss 0.7548 (0.7428)	acc 0.4840 (0.4619)	lr 7.513101e-04
Checkpoint saved to "results/EXP20220516_0/prompt_learner/model.pth.tar-60"
epoch [61/100][5/9]	time 1.937 (2.091)	data 1.310 (1.458)	eta 0:12:22	loss 0.7635 (0.7379)	acc 0.4744 (0.4647)	lr 7.210089e-04
epoch [62/100][5/9]	time 1.895 (2.133)	data 1.269 (1.497)	eta 0:12:18	loss 0.7192 (0.7676)	acc 0.4687 (0.4636)	lr 6.909830e-04
epoch [63/100][5/9]	time 1.973 (2.083)	data 1.350 (1.447)	eta 0:11:41	loss 0.7868 (0.7483)	acc 0.4675 (0.4495)	lr 6.612621e-04
epoch [64/100][5/9]	time 1.905 (2.114)	data 1.272 (1.468)	eta 0:11:33	loss 0.7729 (0.7615)	acc 0.4287 (0.4672)	lr 6.318754e-04
epoch [65/100][5/9]	time 2.071 (2.161)	data 1.414 (1.525)	eta 0:11:29	loss 0.6917 (0.7139)	acc 0.4886 (0.4730)	lr 6.028521e-04
epoch [66/100][5/9]	time 1.751 (2.037)	data 1.130 (1.402)	eta 0:10:31	loss 0.7480 (0.7637)	acc 0.4797 (0.4664)	lr 5.742207e-04
epoch [67/100][5/9]	time 1.851 (2.069)	data 1.223 (1.433)	eta 0:10:22	loss 0.7368 (0.7364)	acc 0.4929 (0.4834)	lr 5.460095e-04
epoch [68/100][5/9]	time 1.889 (2.113)	data 1.255 (1.477)	eta 0:10:17	loss 0.7445 (0.7590)	acc 0.4109 (0.4500)	lr 5.182463e-04
epoch [69/100][5/9]	time 1.923 (2.097)	data 1.298 (1.462)	eta 0:09:53	loss 0.7599 (0.7434)	acc 0.4471 (0.4573)	lr 4.909586e-04
epoch [70/100][5/9]	time 2.059 (2.205)	data 1.437 (1.567)	eta 0:10:04	loss 0.7937 (0.7644)	acc 0.4766 (0.4640)	lr 4.641732e-04
epoch [71/100][5/9]	time 1.821 (2.087)	data 1.194 (1.445)	eta 0:09:12	loss 0.7486 (0.7581)	acc 0.4250 (0.4661)	lr 4.379166e-04
epoch [72/100][5/9]	time 1.971 (2.141)	data 1.347 (1.513)	eta 0:09:08	loss 0.7857 (0.7548)	acc 0.4609 (0.4622)	lr 4.122147e-04
epoch [73/100][5/9]	time 1.906 (2.124)	data 1.280 (1.488)	eta 0:08:44	loss 0.8311 (0.7680)	acc 0.4541 (0.4409)	lr 3.870929e-04
epoch [74/100][5/9]	time 1.936 (2.119)	data 1.289 (1.483)	eta 0:08:24	loss 0.7177 (0.7511)	acc 0.5172 (0.4554)	lr 3.625760e-04
epoch [75/100][5/9]	time 1.972 (2.112)	data 1.339 (1.475)	eta 0:08:03	loss 0.7619 (0.7357)	acc 0.4267 (0.4694)	lr 3.386881e-04
Checkpoint saved to "results/EXP20220516_0/prompt_learner/model.pth.tar-75"
epoch [76/100][5/9]	time 2.030 (2.094)	data 1.378 (1.451)	eta 0:07:40	loss 0.7607 (0.7379)	acc 0.5035 (0.4712)	lr 3.154529e-04
epoch [77/100][5/9]	time 1.891 (2.087)	data 1.262 (1.448)	eta 0:07:20	loss 0.7951 (0.7575)	acc 0.5091 (0.4670)	lr 2.928932e-04
epoch [78/100][5/9]	time 1.944 (2.107)	data 1.315 (1.474)	eta 0:07:05	loss 0.8066 (0.7449)	acc 0.5161 (0.4812)	lr 2.710314e-04
epoch [79/100][5/9]	time 1.928 (2.147)	data 1.302 (1.512)	eta 0:06:54	loss 0.7338 (0.7409)	acc 0.4653 (0.4602)	lr 2.498889e-04
epoch [80/100][5/9]	time 1.966 (2.114)	data 1.343 (1.482)	eta 0:06:28	loss 0.7637 (0.7548)	acc 0.4604 (0.4495)	lr 2.294868e-04
epoch [81/100][5/9]	time 1.829 (2.093)	data 1.208 (1.458)	eta 0:06:06	loss 0.7398 (0.7471)	acc 0.4600 (0.4675)	lr 2.098450e-04
epoch [82/100][5/9]	time 1.882 (2.075)	data 1.252 (1.443)	eta 0:05:44	loss 0.8117 (0.7562)	acc 0.4884 (0.4616)	lr 1.909830e-04
epoch [83/100][5/9]	time 1.899 (2.105)	data 1.263 (1.468)	eta 0:05:30	loss 0.7054 (0.7490)	acc 0.4858 (0.4639)	lr 1.729194e-04
epoch [84/100][5/9]	time 2.003 (2.155)	data 1.375 (1.517)	eta 0:05:18	loss 0.7135 (0.7567)	acc 0.4645 (0.4509)	lr 1.556721e-04
epoch [85/100][5/9]	time 1.908 (2.095)	data 1.281 (1.464)	eta 0:04:51	loss 0.7551 (0.7438)	acc 0.4112 (0.4589)	lr 1.392580e-04
epoch [86/100][5/9]	time 1.961 (2.132)	data 1.328 (1.497)	eta 0:04:37	loss 0.7877 (0.7581)	acc 0.4444 (0.4385)	lr 1.236933e-04
epoch [87/100][5/9]	time 1.911 (2.145)	data 1.287 (1.516)	eta 0:04:19	loss 0.7386 (0.7327)	acc 0.5000 (0.4736)	lr 1.089935e-04
epoch [88/100][5/9]	time 1.880 (2.052)	data 1.243 (1.416)	eta 0:03:49	loss 0.7438 (0.7486)	acc 0.4661 (0.4711)	lr 9.517295e-05
epoch [89/100][5/9]	time 1.911 (2.080)	data 1.283 (1.445)	eta 0:03:34	loss 0.7870 (0.7674)	acc 0.4081 (0.4624)	lr 8.224537e-05
epoch [90/100][5/9]	time 1.877 (2.087)	data 1.251 (1.453)	eta 0:03:16	loss 0.7817 (0.7657)	acc 0.4735 (0.4511)	lr 7.022351e-05
Checkpoint saved to "results/EXP20220516_0/prompt_learner/model.pth.tar-90"
epoch [91/100][5/9]	time 1.928 (2.042)	data 1.304 (1.403)	eta 0:02:53	loss 0.7521 (0.7409)	acc 0.5088 (0.4691)	lr 5.911923e-05
epoch [92/100][5/9]	time 1.865 (2.094)	data 1.243 (1.465)	eta 0:02:39	loss 0.7499 (0.7431)	acc 0.4293 (0.4606)	lr 4.894348e-05
epoch [93/100][5/9]	time 1.875 (2.140)	data 1.238 (1.495)	eta 0:02:23	loss 0.6986 (0.7556)	acc 0.4783 (0.4555)	lr 3.970631e-05
epoch [94/100][5/9]	time 2.059 (2.107)	data 1.399 (1.464)	eta 0:02:02	loss 0.7702 (0.7497)	acc 0.4040 (0.4722)	lr 3.141684e-05
epoch [95/100][5/9]	time 1.942 (2.156)	data 1.322 (1.522)	eta 0:01:45	loss 0.7999 (0.7527)	acc 0.4241 (0.4630)	lr 2.408324e-05
epoch [96/100][5/9]	time 1.939 (2.070)	data 1.309 (1.432)	eta 0:01:22	loss 0.7308 (0.7304)	acc 0.4484 (0.4563)	lr 1.771275e-05
epoch [97/100][5/9]	time 1.962 (2.107)	data 1.322 (1.473)	eta 0:01:05	loss 0.7293 (0.7266)	acc 0.5261 (0.4672)	lr 1.231166e-05
epoch [98/100][5/9]	time 1.875 (2.108)	data 1.255 (1.471)	eta 0:00:46	loss 0.6951 (0.7530)	acc 0.4496 (0.4533)	lr 7.885299e-06
epoch [99/100][5/9]	time 1.899 (2.104)	data 1.275 (1.458)	eta 0:00:27	loss 0.7515 (0.7428)	acc 0.4904 (0.4683)	lr 4.438035e-06
epoch [100/100][5/9]	time 1.902 (2.112)	data 1.279 (1.477)	eta 0:00:08	loss 0.7375 (0.7374)	acc 0.4620 (0.4661)	lr 1.973272e-06
Checkpoint saved to "results/EXP20220516_0/prompt_learner/model.pth.tar-100"
Finished training
Elapsed: 0:30:54
